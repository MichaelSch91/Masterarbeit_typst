== Evaluation der Zahlendarstellung <Hauptteil_Evaluation_Evaluation_der_Zahlendarstellung>
In @einleitung_zahlendarstellung_für_die_logistische_abbildung wurde bereits der Zusammenhang einer höheren Dichte an darstellbaren Zahlen und der genaueren Berechnung des jeweiligen Wertebereichs einer Funktion formuliert. Jedoch wäre es vermutlich ungünstig die entwickelte Zahlendarstellung darüber zu evaluieren und sich einfach mit der Behauptung „besser, da höhere Dichte darstellbarer Zahlen im Bereich, der häufiger von der Funktion erreicht wird“ zufriedenzugeben. Die naheliegendste Überlegung ist vermutlich das Delta zwischen korrektem Ergebnis und dem errechneten Ergebnis zu betrachten. Jedoch stellt sich hier die Frage, wie man das jeweils korrekte Ergebnis für die Generationen der logistischen Abbildung überhaupt mit einem (anderen) Zahlensystem errechnet.\ 
Eine einfache Möglichkeit wäre, das entwickelte System (32 Bit) mit einem deutlich längeren System, wie Double (64 Bit) oder Quadruple (Long Double) (128 Bit) zu vergleichen (@Hauptteil_Evaluation_Evaluieren_mit_Genauigkeit_anderer_Zahlendarstellung). Also mit dem entwickelten System und mit Double bzw. Quadruple die Werte der logistischen Funktion zu berechnen und dann die jeweiligen Generationen zu vergleichen. Aber leider impliziert auch dieses Vorgehen wieder die Annahme, dass eine höhere Dichte an darstellbaren Werten eine bessere Genauigkeit bedeutet. \

Eine weitere, sehr ähnliche Möglichkeit der Evaluation, verglichen zur Evaluation mit einer vorhandenen Zahlendarstellung, könnte sein die Anzahl der Nachkommazahlen zu begrenzen. Dies wurde im Rahmen der Tests zu den möglichen Evaluationsmöglichkeiten durchgeführt und wird in @Anhang_Evaluation_Nachkommastellen etwas ausführlicher beschrieben. Das Kürzen der Nachkommastellen ist für die, in dieser Arbeit entwickelten Zahlendarstellung, keine geeignete Evaluationsmöglichkeit und wurde daher in den @Anhang verschoben. Trotzdem kann mit dem Versuch anschaulich gezeigt werden, warum die Evaluation mit einem anderen System nicht zwingend sinnvoll ist. Bei dem Versuch wurde die logistische Abbildung mit verschiedenen Floats berechnet, die mit der Python Standardbibliothek auf eine bestimmte Nachkommastelle gerundet wurden. Die errechneten Ergebnisse wurden dann zwischen den unterschiedlichen Nachkommastellen ("Berechnung" und "Evaluation", wobei "Evaluation" mehr Nachkommastellen aufweisen musste) verglichen und die Abweichung der jeweiligen Iterationen berechnet. Es wurden Tabellen erstellt, die die Nachkommastellen ($n_1$ und $n_2$), eine festgelegte maximale Abweichung ($Delta_max$) und die Anzahl der Iterationen, bis die maximale Abweichung das erste Mal überschritten wurde. Die Anzahl der Iterationen bis zur ersten Überschreitung von $Delta_max$ wurden als Vergleich eingeführt, da nach dem ersten Überschreiten chaotisches Verhalten auftritt (siehe @abbildung_hauptteil_überprüfung_evaluationsmöglichkeiten_14_17) und nach einer ausreichend großen Anzahl an Iterationen die mittlere Abweichung der einzelnen Iterationen ($Delta = "Evaluation" - "Berechnung" $, $ macron(Delta)=(sum_(I=0)^n Delta) /n)$ nicht mehr als Vergleich zu verwenden ist. Die durchschnittliche Abweichung beträgt dann ungefähr $1/3$, also die durchschnittliche Abweichung von zwei vollkommen zufälligen Arrays im Zahlenbereich $[0;1]$. @abbildung_hauptteil_überprüfung_evaluationsmöglichkeiten_10_12 zeigt den chaotischen Verlauf nach 500 Iterationen, wordurch klar erkennbar wird, dass die Werte ab einem gewissen Punkt vollkommen unterschiedlich verlaufen.

#figure(
  image("1_0_Abbildungen/Abweichungen_Nachkommastellen_14_17_0bis100.png", width: 95%),
  caption: [
    Logistische Abbildung mit r = 3,9 mit 14 und 17 Nachkommastellen der Floats berechnet
  ],
) <abbildung_hauptteil_überprüfung_evaluationsmöglichkeiten_14_17>

Auf den ersten Blick könnte man bei dieser Vergleichsmöglichkeit vermuten, dass je größer die Zahl der Nachkommastellen wird, desto mehr Iterationen innerhalb der Toleranzgrenze liegen werden und auch, dass naheliegende Anzahlen der Nachkommastellen (z.B. "Berechnung" = 15 und "Evaluation" = 16) zu mehr Iterationen bis zum Abbruchkriterium führen. Die angehängten Tabellen in @Anhang_Evaluation_Nachkommastellen zeigen jedoch nur Ersteres und auch das unterliegt einigen Schwankungen. Die Anzahl der Iterationen bis $Delta_max$ überschritten wird nimmt mit mehr Nachkommazahlen zu, sinkt aber z.B. beim Übergang von 10 auf 11 Nachkommastellen bei r = 3,9, bei r = 3,92 steigt die Anzahl der Iterationen dagegen gleichmäßig. Desweiteren ist auch die Berechnung mit "benachbarten" Nachkommazahlen (in fast allen Fällen) nicht besser. Weiter auseinanderliegende Nachkommastellen mit konstanter Nachkommastelle der "Berechnung" weißen meist mehr Iterationen bis zum Abbruchkriterium auf. Beim Beispiel von 2 und 3 Nachkommastellen kann lediglich auf eine Abweichung in Schritten von 0,001 und maximal 0,005 zwischen den Berechnungspunkten zurückgegriffen werden, bei einem Beispiel von 2 und 4 sind es hingegen schon Schritte von 0,0001, bei einem durch die Rundungen gleichbleibenden Maximum von 0,005. \
Nach diesen Erkenntnissen stellt sich die Frage, wie man überhaupt ein korrektes Ergebnis für die Berechnung der Werte der logistischen Abbildung erhalten kann, wenn man sie mit einem endlichen Zahlensystem (digital, unabhängig von der Anazahl an Bit für die Zahlendarstellung) am Computer errechnet oder ob diese Herangehensweise möglicherweise gar nicht zielführend ist.

#figure(
  image("1_0_Abbildungen/Nachkommastellen_10_12_500bis550.png", width: 95%),
  caption: [
    Logistische Abbildung mit r = 3,9 mit 10 und 12 Nachkommastellen der Floats berechnet
  ],
) <abbildung_hauptteil_überprüfung_evaluationsmöglichkeiten_10_12>

Daher könnte es notwendig sein, die Möglichkeit der Evaluation über die Periodizität zu verwenden (@Hauptteil_Evaluation_evaluieren_mit_periodizität). Bei Eingaben für die logistische Abbildung, auch die, die sich nicht wie in @abbildung_logistischeAbbildung_einschwingen gezeigt einschwingen, werden sich bei endlicher Genauigkeit der Zahlendarstellung nach einer bestimmten Periodenlänge (Anzahl an Iterationen) die Ergebnisse wiederholen. Es wird angenommen, dass je besser die Zahlendarstellung ist, desto weniger gleiche Zahlen müssen für das Ergebnis der jeweils nächsten Iteration verwendet werden (Kollisionsresistenz) @lit_flajolet_odlyzko_random_mapping_statistics. Das bedeutet, dass eine bessere Zahlendarstellung mehr Iterationen benötigt, bevor sie wieder einen bereits zuvor erhaltenen Wert erreicht. Es würde gelten: Je höher die Periodenlänge, desto besser die Zahlendarstellung. Auch hier soll der Vergleich zu bereits bekannten Zahlendarstellungen (float, double) erfolgen.

#text(red)[@lit_flajolet_odlyzko_random_mapping_statistics ausführlicher erklären]
